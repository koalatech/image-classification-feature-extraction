{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from img2vec_pytorch import Img2Vec\n",
    "from PIL import Image\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koala\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\koala\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "\n",
    "img2vec = Img2Vec()\n",
    "\n",
    "data_dir = './dataset2'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'val')\n",
    "\n",
    "\n",
    "\n",
    "data = {}\n",
    "for j, dir_ in enumerate([train_dir, val_dir]):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for category in os.listdir(dir_):\n",
    "        for img_path in os.listdir(os.path.join(dir_, category)):\n",
    "            img_path_ = os.path.join(dir_, category, img_path)\n",
    "            \n",
    "            img = Image.open(img_path_).convert('RGB')\n",
    "\n",
    "            img_features = img2vec.get_vec(img)\n",
    "\n",
    "            features.append(img_features)\n",
    "            labels.append(category)\n",
    "\n",
    "    data[['training_data', 'validation_data'][j]] = features\n",
    "    data[['training_labels', 'validation_labels'][j]] = labels\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['training_data', 'training_labels', 'validation_data', 'validation_labels'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "model.fit(data['training_data'], data['training_labels'])\n",
    "\n",
    "# test performance\n",
    "y_pred = model.predict(data['validation_data'])\n",
    "score = accuracy_score(y_pred, data['validation_labels'])\n",
    "\n",
    "print(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "with open('./model.p', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cloudy']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from img2vec_pytorch import Img2Vec\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "with open('model.p', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "img2vec = Img2Vec()\n",
    "\n",
    "image_path = './example/test_images/cloud.jpg'\n",
    "\n",
    "img = Image.open(image_path)\n",
    "\n",
    "features = img2vec.get_vec(img)\n",
    "\n",
    "pred = model.predict([features])\n",
    "\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
